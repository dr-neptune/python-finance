#+TITLE: Chapter 16: Automated Trading

This chapter covers the following topics:

- Capital Management
  Depending on the strategy characteristics and the trading capital available, the Kelly criterion helps with sizing the trades
- ML-Based Trading Strategy
  The strategy needs to be backtested thoroughly w.r.t performance and risk characteristics
- Online Algorithms
  To deploy the strategy, it needs to be translated into an online algorithm that works with incoming stream data in real time
- Infrastructure and Deployment
- Logging and Monitoring

* Capital Management

A centrail question in algo trading is how much capital to deploy to a given strategy given the total available capital.
Most will agree that the /maximization of long-term wealth/ is a good candidate objective. This is what Edward Thorpe had in mind when he derived the /Kelly criterion/ for investing.

** The Kelly Criterion in a Binomial Setting

The Kelly Criterion derives the /optimal fraction/ $f$ of available capital to bet per round of betting

#+begin_src python
import math
import time
import numpy as np
import pandas as pd
import datetime as dt
import cufflinks as cf
import matplotlib.pyplot as plt
np.random.seed(1000)
import matplotlib
matplotlib.use('tkAgg')
plt.style.use('seaborn')


p = 0.55             # fix the probability of heads
f = p - (1 - p)      # calculate optimal fraction according to Kelly criterion
f

I = 50               # number of series to be simulated
n = 100              # number of trials per series

def run_simulation(f):
    # instantiate an ndarray to store simulation results
    c = np.zeros((n, I))
    c[0] = 100  # initialize starting capital with 100
    for i in range(I):             # series simulations
        for t in range(1, n):      # the series itself
            o = np.random.binomial(1, p)   # simulate the tossing of a coin
            if o > 0:
                c[t, i] = (1 + f) * c[t - 1, i]  # if win, add the win to the capital
            else:
                c[t, i] = (1 - f) * c[t - 1, i]  # otherwise, remove the amount from the capital
    return c

c_1 = run_simulation(f)
c_1.round(2)

# 50 simulated series with 100 trials each (red line = average)
plt.figure()
plt.plot(c_1, 'b', lw=0.5)
plt.plot(c_1.mean(axis=1), 'r', lw=2.5)
plt.show()

c_2 = run_simulation(0.05)
c_3 = run_simulation(0.25)
c_4 = run_simulation(0.5)

plt.figure()
plt.plot(c_1.mean(axis=1), 'r', label='$f^*=0.1$')
plt.plot(c_2.mean(axis=1), 'b', label='$f^*=0.05$')
plt.plot(c_3.mean(axis=1), 'y', label='$f^*=0.25$')
plt.plot(c_4.mean(axis=1), 'm', label='$f^*=0.5$')
plt.legend(loc=0)
plt.show()
#+end_src

** The Kelly Criterion for Stocks and Indices

One has to maximize the following quantity to achieve maximum long-term wealth when investing in the stock:

For finite time:

$G_n(f) = r + (\mu - r) \cdot f - \frac{\sigma^2}{2} \cdot f^2 + \mathcal{O}(\frac{1}{\sqrt{n}})$

for infinitely many trading points in time -- i.e. continuous trading:

$G_\infty (f) = r + (\mu - r) \cdot f - \frac{\sigma^2}{2} \cdot f^2$

The optimal fraction $f$ then is given through the first-order condition by the expression:

$f^* = \frac{\mu - r}{\sigma^2}$

i.e. the expected excess return of the stock over the risk-free rate divided by the variance of the returns.


A real-world example:

The trading strategy under consideration is simply a /passive long position in the S&P 500 index/.

#+begin_src python
raw = pd.read_csv('data/tr_eikon_eod_data.csv')
symbol = '.SPX'

data = raw[symbol].to_frame()
data['returns'] = np.log(data / data.shift(1)).dropna()

mu = data.returns.mean() * 252  # annualized return
sigma = data.returns.std() * 252 ** 0.5  # annualized volatility
r = 0.0  # set the risk-free rate to 0
f = (mu - r) / sigma ** 2  # calculate the optimal Kelly fraction to be invested in the strategy
#+end_src

The following code simulates the application of the Kelly criterion and the optimal leverage ratio. For simplicity and comparison reasons, the initial equity is set to 1 while the initially invested total capital is set to $f^*$. Depending on the performance of the capital deployed to the strategy, the total capital itself is adjusted daily according to the available equity.

#+begin_src python
equs = []
def kelly_strategy(f):
    global equs
    equ = f'equity_{f:.2f}'
    equs.append(equ)
    cap = f'capital_{f:.2f}'
    data[equ] = 1                # a new column for equity initialized to 1
    data[cap] = data[equ] * f    # a new column for capital initialized to f
    for i, t in enumerate(data.index[1:]):
        t_1 = data.index[i]      # pick the right datetimeindex value for previous states
        # calculate new capital position given the return
        data.loc[t, cap] = data[cap].loc[t_1] * math.exp(data['returns'].loc[t])
        # adjust the equity value according to capital position preference
        data.loc[t, equ] = data[cap].loc[t] - data[cap].loc[t_1] + data[equ].loc[t_1]
        # adjust the capital position given the new equity position and fixed leverage ratio
        data.loc[t, cap] = data[equ].loc[t] * f

kelly_strategy(f * 0.5)    # simulate kelly criterion for 1/2 f
kelly_strategy(f * 0.66)   # 2/3 f
kelly_strategy(f)          # 1 f

print(data[equs].tail())

ax = data['returns'].cumsum().apply(np.exp).plot(legend=True)
data[equs].plot(ax=ax, legend=True)
plt.show()
#+end_src

* ML-Based Strategy

This section combines an ML-based approach for predicting the direction of market price movements with historical data from the FXCM rest api to backtest an algorithmic trading strategy for the EUR/USD currency pair. It uses vectorized backtesting, taking into account this time the bid-ask spread as proportional transaction costs. It also adds a more in-depth analysis of the risk characteristics of the trading strategy tested.

** Vectorized Backtesting

#+begin_src python
import fxcmpy
api = fxcmpy.fxcmpy(config_file='fxcm.cfg')

data = api.get_candles('EUR/USD', period='m5',
                       start='2018-06-01 00:00:00',
                       stop='2018-06-30 00:00:00')

data.iloc[-5:, 4:]

# calculate the average bid-ask spread
spread = (data['askclose'] - data['bidclose']).mean()

# calculate the mid close prices from the ask and bid close prices
data['midclose'] = (data['askclose'] + data['bidclose']) / 2

# calculate the average proportional transaction costs given the average spread
# and average mid close price
ptc = spread / data['midclose'].mean()

data['midclose'].plot(legend=True)
plt.show()

# create binarized data
data['returns'] = np.log(data['midclose'] / data['midclose'].shift(1)).dropna()

lags = 5

cols = []
for lag in range(1, lags + 1):
    col = f'lag_{lag}'
    # creates the lagged return data given the number of lags
    data[col] = data['returns'].shift(lag)
    cols.append(col)

data = data.dropna()

# transform the feature values to binary data
data[cols] = np.where(data[cols] > 0, 1, 0)

# transform the return data to directional label data
data['direction'] = np.where(data['returns'] > 0, 1, -1)


data[cols + ['direction']].head()

# fit model
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

model = SVC(C=1, kernel='linear', gamma='auto')
split = int(len(data) * .8)
train = data.iloc[:split].copy()
test = data.iloc[split:].copy()

model.fit(train[cols], train['direction'])
test['position'] = model.predict(test[cols])

accuracy_score(train['direction'], model.predict(train[cols]))
accuracy_score(test['direction'], test['position'])
#+end_src

It is well known that the hit ratio is only one aspect of success in financial trading. Also crucial are, among other things, the transaction costs implied by the trading strategy and getting important trades right.

The following code takes into account the proportional transaction costs based on the average ask-bid spread.

#+begin_src python
# derive log returns for the ML-based algorithmic trading strategy
test['strategy'] = test['position'] * test['returns']

# calculate number of trades implied by the trading strategy based on changes in the position
sum(test['position'].diff() != 0)

# whenever a trade takes place, the proportional transaction costs are subtracted from
# the strategy's log return on that day
test['strategy_tc'] = np.where(test['position'].diff() != 0,
                               test['strategy'] - ptc,
                               test['strategy'])


test[['returns', 'strategy', 'strategy_tc']].sum().apply(np.exp)

test[['returns', 'strategy', 'strategy_tc']].cumsum().apply(np.exp).plot()
plt.show()
#+end_src

** Optimal Leverage

Equipped with the trading strategy's log returns data, the mean and variance values can be calculated in order to derive the optimal leverage according to the Kelly criterion.

#+begin_src python
# annualized mean returns
mean = test[['returns', 'strategy_tc']].mean() * len(data) * 12
mean

# annualized variances
var = test[['returns', 'strategy_tc']].var() * len(data) * 12
var

# annualized volatilities
vol = var ** 0.5
vol

# optimal leverage according to the Kelly criterion (full Kelly)
mean / var

# optional leverage (half Kelly)
mean / var ** 0.5

# performance of algorithmic trading strategy for different leverage values
to_plot = ['returns', 'strategy_tc']

for lev in list(range(10, 60, 10)):
    label = f'lstrategy_tc_{lev}'
    test[label] = test['strategy_tc'] * lev
    to_plot.append(label)

test[to_plot].cumsum().apply(np.exp).plot()
plt.show()
#+end_src

** Risk Analysis

The risk analysis that follows assumes a leverage ratio of 30.

First the maximum drawdown and the longest drawdown period are calculated. /Maximum drawdown/ is the largest loss (dip) after a recent high. Accordingly, the /longest drawdown period/ is the longest period that the trading strategy needs to get back to a recent high.

#+begin_src python
# initial equity
equity = 3333

# relevant log returns time series
risk = pd.DataFrame(test['lstrategy_tc_30'])

# scaled by the initial equity
risk['equity'] = risk['lstrategy_tc_30'].cumsum().apply(np.exp) * equity

# cumulative maximum values over time
risk['cummax'] = risk['equity'].cummax()

# drawdown values over time
risk['drawdown'] = risk['cummax'] - risk['equity']

# max drawdown value
risk['drawdown'].max()

# point in time when it happens
t_max = risk['drawdown'].idxmax()
t_max
#+end_src

Technically a (new) high is characterized by a drawdown value of 0. The drawdown period is the time between 2 such highs.

#+begin_src python
# identifies highs for which the drawdown must be 0
temp = risk['drawdown'][risk['drawdown'] == 0]

# calculates the timedelta values between all highs
periods = (temp.index[1:].to_pydatetime() -
           temp.index[:-1].to_pydatetime())

# the longest drawdown period in seconds
t_per = periods.max()


risk[['equity', 'cummax']].plot()
plt.axvline(t_max, c='r', alpha=0.5)
plt.show()
#+end_src

Another important risk measure is value-at-risk (VaR). It is quoted as a currency amount and represents the maximum loss to be expected given both a certain time horizon and confidence level.

#+begin_src python
import scipy.stats as scs

# define percentiles to check
percs = np.array([0.01, 0.1, 1., 2.5, 5.0, 10.0])
risk['returns'] = np.log(risk['equity'] / risk['equity'].shift(1))

# calculate the VaR values given the percentile values
VaR = scs.scoreatpercentile(equity * risk['returns'], percs)

def print_var():
    print('%16s %16s' % ('Confidence Level', 'Value-at-Risk'))
    print(33 * '-')
    for pair in zip(percs, VaR):
        # translate percentile values into confidence levels and the VaR values to positive values
        print('%16.2f %16.3f' % (100 - pair[0], -pair[1]))

print_var()

# calculate the VaR values for a time horizon of one hour

# resample the data from 5 minute to 1 hour bars
hourly = risk.resample('1H', label='right').last()
hourly['returns'] = np.log(hourly['equity'] / hourly['equity'].shift(1))

# recalculate the VaR values for the resampled data
VaR = scs.scoreatpercentile(equity * hourly['returns'], percs)

print_var()
#+end_src

** Persisting the Model Object

#+begin_src python
import pickle

pickle.dump(model, open('algorithm.pkl', 'wb'))
#+end_src

* Online Algorithm

In practice, when deploying the trading algorithm in financial markets, it must consume data piece-by-piece as it arrives to predict the direction of the market movement for the next time interval (bar).

The code that transforms the offline trading algorithm into an online trading algorithm mainly addresses the following issues:

- Tick Data
  it arrives in real time
- Resampling
  tick data needs to be resampled to the appropriate bar size given the trading algorithm
- Prediction
  The algo generates a prediction for the direction of the market movement over the relevant time interval
- Orders
  Given current position and prediction ("signal") generated by the algo, an order is placed or the position is kept

#+begin_src python
algorithm = pickle.load(open('algorithm.pkl', 'rb'))

sel = ['tradeId', 'amountK', 'currency', 'grossPL', 'isBuy']

def print_positions(pos):
    print('\n\n' + 50 * '=')
    print('Going {}.\n'.format(pos))
    time.sleep(1.5)  # wait for order to be executed and reflected in the open positions
    print(api.get_open_positions()[sel])  # print open positions
    print(50 * '=' + '\n\n')

# set params
symbol = 'EUR/USD'      # instrument symbol to be traded
bar = '15s'             # bar length for resampling
amount = 100            # the amount, in thousands, to be traded
position = 0            # the initial position ('neutral')
min_bars = lags + 1     # minimum # of resampled bars required for the first prediction and trade to be possible
df = pd.DataFrame()     # empty DF to be used later for the resampled data

def automated_strategy(data, dataframe):
    global min_bars, position, df
    # captures the length of the dataframe obj with the tick data
    ldf = len(dataframe)
    # resamples the tick data to the defined bar length
    df = dataframe.resample(bar, label='right').last().ffill()
    if ldf % 20 == 0:
        print('%3d' % len(dataframe), end=',')
    if len(df) > min_bars:
        min_bars = len(df)
        df['Mid'] = df[['Bid', 'Ask']].mean(axis=1)
        df['Returns'] = np.log(df['Mid'] / df['Mid'].shift(1))
        df['Direction'] = np.where(df['Returns'] > 0, 1, -1)
        # picks the relevant feature values for all lags
        features = df['Direction'].iloc[-(lags + 1):-1]
        # reshape them to a form that the model can use for prediction
        features = features.values.reshape(1, -1)
        # generate prediction value (+-1)
        signal = algorithm.predict(features)[0]

        # conditions to enter (or keep) a long position
        if position in [0, -1] and signal == 1:
            api.create_market_buy_order(symbol, amount - position * amount)
            position = 1
            print_positions('LONG')
        # conditions to enter (or keep) a short position
        elif position in [0, -1] and signal == -1:
            api.create_market_sell_order(symbol, amount + position * amount)
            position = -1
            print_positions('SHORT')

    # condition to stop trading and close out any open positions
    if len(dataframe) > 350:
        api.unsubscribe_market_data('EUR/USD')
        api.close_all()


# copied from book, still not using "data" param
# def automated_strategy(data, dataframe):
#     global min_bars, position, df
#     ldf = len(dataframe)
#     df = dataframe.resample(bar, label='right').last().ffill()
#     if ldf % 20 == 0:
#         print('%3d' % len(dataframe), end=',')
#     if len(df) > min_bars:
#         min_bars = len(df)
#         df['Mid'] = df[['Bid', 'Ask']].mean(axis=1)
#         df['Returns'] = np.log(df['Mid'] / df['Mid'].shift(1))
#         df['Direction'] = np.where(df['Returns'] > 0, 1, -1)
#         features = df['Direction'].iloc[-(lags + 1):-1]
#         features = features.values.reshape(1, -1)
#         signal = algorithm.predict(features)[0]
#         if position in [0, -1] and signal == 1:
#             api.create_market_buy_order(
#                 symbol, amount - position * amount)
#             position = 1
#             print_positions('LONG')
#         elif position in [0, 1] and signal == -1:
#             api.create_market_sell_order(
#                 symbol, amount + position * amount)
#             position = -1
#             print_positions('SHORT')
#     if len(dataframe) > 350:
#         api.unsubscribe_market_data('EUR/USD')
#         api.close_all()
#+end_src

*
